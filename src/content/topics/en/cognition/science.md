---
title: "Science, scientific method, and scientific thinking"
description: "This work explores the fundamental foundations of scientific knowledge, analyzing the nature of science, the structure of the scientific method, and the principles of scientific thinking."
level: 4
tags: ["thinking", "science", "methodology"]
related: ["/topics/en/cognition/brain", "/topics/en/cognition/healthy-brain", "/topics/en/cognition/rationality", "/topics/en/society/scientific-community", "/topics/en/cognition/fallacies", "/topics/en/cognition/cognitive-biases", "/topics/en/cognition/positive-transfer", "/topics/en/cognition/relativity"]
meme: "/assets/memes/en/Scientific-Method-1024x1024.jpg"
category: "cognition"
difficulty: "intermediate"
publishedAt: 2024-01-10
lang: "en"
---

# Science, the Scientific Method, and Scientific Thinking

## 1. Introduction

“If we are to name as divine everything we don’t understand, how much of the divine will there be?” — this question, posed by Carl Sagan, captures the essence of the scientific approach to understanding the world. Science is not merely a collection of facts or dogmas, but a dynamic process of constantly revising our representations of reality.

In the modern world, where information spreads at unprecedented speed and pseudoscientific theories often disguise themselves as serious research, understanding the nature of science and the scientific method becomes critically important not only for scientists but for every educated person.

This work aims to explore the fundamental principles of scientific inquiry, analyze the strengths and weaknesses of the traditional scientific method, and consider alternative approaches to rational thinking in situations where classical science proves powerless.

---

## 2. The Nature and Definition of Science

### 2.1. An Evolutionary Perspective on Science

Richard Feynman offers an evolutionary understanding of science: “On our planet, in the course of the evolution of life, intelligent beings appeared… Gradually they developed until some creatures learned to acquire experience more quickly and even pass it on to others.” This process of accumulating knowledge, which Feynman calls “time-binding,” became the foundation for the emergence of science.

However, the mere accumulation of knowledge contained a fundamental problem: “Along with useful ideas, harmful ones were also passed on.” Science arose as a response to this problem — as a way to separate reliable knowledge from prejudice and error.

### 2.2. Defining Science Through Skepticism

According to Feynman, **the essence of science lies in recognizing that everything should be rechecked through new experience, rather than unquestioningly believed based on the legacy of the past**. This definition highlights the fundamentally critical nature of the scientific approach.

Feynman also offers a provocative definition: **“Science is the belief in the ignorance of experts.”** This does not mean rejecting authority but rather emphasizing that in science, authority is not the final argument. When someone says “science claims,” the better question to ask is: “How exactly was this established? By what methods? Where can the original sources be found?”

![science_args](/assets/memes/en/doubt_right.jpg)

### 2.3. Science as a Source of Spirituality

It is important to note that scientific inquiry does not contradict the spiritual needs of humans. As Sagan emphasizes: “Science is not only compatible with spirituality; it is a profound source of spirituality.” Understanding that “trees are made mostly of air” and that “the heat released in a flame is sunlight that once helped the air become a tree” reveals a beauty and wonder of the world inaccessible to superficial observation.

---
## The Scientific Method

### 3.1. What is the Scientific Method and Why Do We Need It?

Imagine a situation: your friend claims their new diet helped them lose 10 kilograms in a month. Should you trust their word and start this diet? The scientific method is a set of principles and procedures that helps distinguish reliable information from misconceptions, coincidences, and prejudices.

**Why is the scientific method necessary?**

1.  **Minimizing Human Error**: Our brains are prone to cognitive biases—we see patterns where none exist, remember only confirming facts, and ignore contradictory evidence.

2.  **Objectivity**: The scientific method creates a system of checks and balances that helps obtain results that do not depend on the researcher's personal biases.

3.  **Reproducibility**: Anyone can repeat a study and get the same results, which confirms their reliability.

4.  **Accumulation of Knowledge**: Each new study builds upon previous ones, creating a strong foundation for understanding the world.

### 3.2. The Classical Scientific Method Algorithm

Traditionally, the scientific method is described through a simple sequence of steps:

1.  **Observation** — noticing something interesting or unusual in the world around us.
2.  **Question** — formulating what we want to understand.
3.  **Hypothesis** — proposing an educated guess about how things work.
4.  **Prediction** — deciding what should happen if our hypothesis is correct.
5.  **Experiment** — testing the prediction under controlled conditions.
6.  **Analysis** — comparing the results with the expected outcome.
7.  **Conclusion** — deciding whether our hypothesis is supported or not.

**A Simple Example**:
- *Observation*: The plants on the windowsill grow towards the window.
- *Question*: Why do plants lean towards the window?
- *Hypothesis*: Plants are attracted to light.
- *Prediction*: If we place a lamp on the other side of the plant, it should turn towards the lamp.
- *Experiment*: We place the lamp and observe for a week.
- *Result*: The plant indeed turns towards the lamp.
- *Conclusion*: The hypothesis is supported (but it is only a specific case).

---

### 3.3. A Detailed Guide to Scientific Research

#### Stage 1: Problem Definition and Hypothesis Formulation

**Step 1.1**: Identifying the Problem

Every study begins with curiosity or a puzzling observation. But to turn curiosity into a scientific problem, you must conduct a **literature review**—to learn what is already known on the topic.

*Example*: You've noticed that students who drink coffee before an exam seem to get better grades. Before you investigate this question, you need to find out:
- Have similar studies been conducted before?
- What were the results?
- What methods were used?
- Where are the gaps in knowledge?

**How to find information?**
- Academic search engines: Google Scholar, PubMed, ResearchGate
- Library databases
- Review articles—they summarize existing research.
- Meta-analyses—statistical integration of results from multiple studies.

**Step 1.2**: Formulating a Research Question

A good research question should meet the **FINER** criteria:

- **F**easible: Do you have the time, money, participants, and equipment to answer this question?
    - *Bad*: "Does coffee affect human intelligence?" (too broad, indefinite)
    - *Good*: "Does 100 mg of caffeine improve short-term memory in students aged 18-25, 30 minutes after intake?"

- **I**nteresting: Is this question of interest to you, other scientists, and society?

- **N**ovel: Does the answer add something to existing knowledge? You should not simply repeat what has already been done.

- **E**thical: Will the research harm participants? Experiments with humans or animals require approval from an ethics committee.

- **R**elevant: Does the answer have practical or theoretical significance?

**Step 1.3**: Formulating Hypotheses

A hypothesis is your educated guess about what the answer to the research question will be. In science, **two opposing hypotheses** are always formulated:

The **Null Hypothesis (H₀)** states that there is **NO** effect or relationship:
- *Example*: "100 mg of caffeine has no effect on the memory test scores of students."

The **Alternative Hypothesis (H₁)** states that there **IS** an effect or relationship:
- *Example*: "Students who have taken 100 mg of caffeine show statistically significantly better results on short-term memory tests than students who have taken a placebo."

**Why this way?** The logic of the scientific method is based on the principle "guilty until proven innocent" in reverse—we assume there is no effect (H₀) until we have convincing evidence to the contrary. This protects us from false discoveries.

---

#### Stage 2: Planning the Research Design

**What is research design?**
It's the plan for how you will collect and analyze data to answer your question. The choice of design is critical—a poor design can make even the most meticulous research useless.

**Types of Studies**

**OBSERVATIONAL STUDIES**—you simply observe without intervening.

*When to use*: When an experiment is impossible or unethical. For example, you cannot make people smoke to study the effect of smoking on cancer.

*Types of observational studies*:

1.  **Cross-sectional studies**—a "snapshot" at a specific moment.
    - *Example*: A survey of 1000 students about their sleep habits and academic performance today.
    - *Pros*: Fast, inexpensive.
    - *Cons*: Impossible to establish cause and effect.

2.  **Longitudinal studies**—tracking over time.
    - *Example*: Observing the same students over four years of their studies.
    - *Pros*: You can see changes.
    - *Cons*: Time-consuming, expensive, people drop out of the study.

3.  **Case-control studies**—comparing those with a condition to those without.
    - *Example*: Comparing students with and without depression based on their habits.

**EXPERIMENTAL STUDIES**—you actively change something.

*When to use*: When you want to establish a cause-and-effect relationship.

**Key concepts in an experiment:**

- **Independent Variable**—what you change (in the caffeine example: the presence/absence of caffeine).
- **Dependent Variable**—what you measure (the memory test score).
- **Experimental Group**—receives the intervention (caffeine).
- **Control Group**—does not receive the intervention (placebo).

**What is a placebo and why is it needed?**
A placebo is a "dummy" that looks like the real treatment but contains no active substance. In our example, it could be a tablet without caffeine, but visually indistinguishable from the caffeine tablet.

*Why is a placebo needed?* People may feel better simply because they think they are receiving a treatment. This is called the **placebo effect**. A control group with a placebo helps separate the real effect of the drug from the effect of expectation.

**RANDOMIZATION**—random assignment of participants to groups.

*Why is this necessary?* Imagine that only high-achieving students end up in the caffeine group and only low-achieving students in the placebo group. Any difference in results could then be explained by their initial ability level, not by the caffeine.

*How is it done?*
- Simple randomization: a coin flip or a random number generator.
- Stratified randomization: first, you divide people by important characteristics (gender, age), then randomly assign within each group.

*Example*: We have 100 students. A random number generator decides: student #1—Group A (caffeine), student #2—Group B (placebo), and so on.

---

#### Stage 3: Objective Data Collection

**Why is objectivity so important?**
The human brain is not a perfect tool for scientific observation. We are prone to:
- Seeing what we want to see.
- Remembering vivid but unrepresentative cases.
- Unconsciously influencing the outcome with our expectations.

**Main threats to objectivity and how to combat them:**

**1. Researcher bias**

*Problem*: The researcher might unconsciously influence participants or interpret data in a desired direction.

*Solution—blinding methods*:
- **Single-blind study**: participants don't know which group they are in.
    - *Example*: both the caffeine tablet and the placebo look identical.
- **Double-blind study**: neither the participants nor the researchers know who is in which group.
    - *Example*: tablets are coded with numbers, the code is revealed only after data analysis.
- **Triple-blind study**: even the data analyst doesn't know the coding until the analysis is complete.

**2. Sampling bias**

*Problem*: Your sample does not represent the entire population you want to draw conclusions about.

*Example of a bad sample*: A study on the effect of caffeine only among students from one computer science department (they might react differently to caffeine due to habit).

*Solutions*:
- **Random sampling**: every person in the population of interest has an equal chance of being included in the study.
- **Stratified sampling**: divide the population into groups (by gender, age, major) and select random representatives from each group.
- **Cluster sampling**: randomly select groups (e.g., several universities), then include everyone from the selected groups.

**3. Measurement error**

*Problem*: Inaccuracies in how you measure the results.

*Solutions*:
- **Standardization of procedures**: all participants undergo the test under the same conditions (same time of day, same room, same instructions).
- **Calibration of instruments**: regular checking of equipment.
- **Multiple measurements**: measure several times and take the average.
- **Validated tests**: use established and proven measurement methods.

*Standardization example*: All participants come at the same time of day (e.g., 10 AM) because memory performance changes throughout the day. All receive identical instructions written as text to avoid differences in verbal explanations.

**Ethical principles of data collection**

**Informed consent**—participants must understand:
- The purpose of the study (in general terms).
- What will be done to them.
- What the risks are.
- That they can withdraw at any time.

**Confidentiality**:
- Participant data should not be linked to their names.
- Results are published only in an aggregated form.
- Only members of the research team have access to the data.

**Minimizing harm**:
- Procedures should not cause physical or psychological harm.
- If the study might cause stress, participants are warned and provided with support.

---

#### Stage 4: Statistical Data Analysis

**Why is statistics needed?**
Data alone is just a set of numbers. Statistics transforms these numbers into answers to questions. It helps us understand: are the observed differences a real effect or just a coincidence?

**TWO TYPES OF STATISTICAL ANALYSIS**

**DESCRIPTIVE STATISTICS**—describes your data with simple numbers.

*What it's for*: to understand the main characteristics of your data, check for errors, and prepare for the main analysis.

**1. Measures of Central Tendency**—where the "center" of your data is:

- **Arithmetic Mean (x̄)**
    - *Formula*: x̄ = Σx/n (sum of all values divided by their count).
    - *Example*: Memory test scores in the caffeine group: 85, 90, 78, 95, 88.
    - *Calculation*: (85+90+78+95+88)/5 = 436/5 = 87.2.
    - *When to use*: when data is approximately normally distributed.
    - *Drawback*: sensitive to outliers (extreme values).

- **Median**—the value that divides the sample in half.
    - *Example*: The same data, sorted: 78, 85, 88, 90, 95.
    - *Median*: 88 (the middle element).
    - *When to use*: when there are outliers or the data is skewed.
    - *Advantage*: not sensitive to outliers.

- **Mode**—the most frequently occurring value.
    - *Example*: if three people in the group scored 85, and the rest had different scores, then the mode = 85.
    - *When to use*: for categorical data (eye color, major).

**2. Measures of Dispersion**—how different the data points are from each other:

- **Range** = Maximum - Minimum
    - *Example*: 95 - 78 = 17.
    - *Drawback*: depends only on the two extreme values.

- **Standard Deviation (σ or s)**—the most important measure of dispersion.
    - *Formula for a sample*: s = √[Σ(x-x̄)²/(n-1)].
    - *What it means*: the average deviation of each value from the mean.
    - *Interpretation*:
        - Small σ = data is close to the mean (results are similar).
        - Large σ = data is widely scattered (high variability).

**Step-by-step calculation of standard deviation:**
Data: 85, 90, 78, 95, 88; Mean = 87.2

| x | (x - x̄) | (x - x̄)² |
|---|---------|----------|
| 85 | 85-87.2 = -2.2 | 4.84 |
| 90 | 90-87.2 = 2.8 | 7.84 |
| 78 | 78-87.2 = -9.2 | 84.64 |
| 95 | 95-87.2 = 7.8 | 60.84 |
| 88 | 88-87.2 = 0.8 | 0.64 |

Sum of (x-x̄)² = 158.8
s = √[158.8/(5-1)] = √[158.8/4] = √39.7 = 6.3

**INFERENTIAL STATISTICS**—draws conclusions about a population based on a sample.

*Core idea*: we have data from a small group of people (a sample), but we want to draw conclusions about all people (the population).

**Key Concepts:**

**P-value**—the most important concept in statistics.
- *Definition*: the probability of obtaining the observed result (or an even more extreme one) if the null hypothesis is true.
- *In simple terms*: "What is the likelihood that this difference is just a coincidence?"
- *Interpretation*:
    - p < 0.05 (5%) = the result is "statistically significant" → reject H₀.
    - p ≥ 0.05 = the result is "statistically non-significant" → we cannot reject H₀.

*Example*: If p = 0.03, this means: "If caffeine truly has no effect on memory, the probability of getting this large (or larger) a difference in results is 3%." Since 3% < 5%, we say the result is statistically significant.

**Confidence Interval**
- *Definition*: a range of values within which the true value of the effect in the population lies with a certain probability (usually 95%).
- *Example*: "We are 95% confident that caffeine improves memory test scores by between 3 and 12 points."
- *Interpretation*: if the interval for the difference does not include zero, the effect is statistically significant.

**CHOOSING A STATISTICAL TEST**

The choice depends on your research question and the type of data:

| Research Question | Data Type | Statistical Test | Example of Use |
|-------------------|-----------|------------------|----------------|
| **Compare the means of two groups** | Continuous data, normal distribution | **Student's t-test** | Compare memory scores: caffeine group vs. placebo group |
| **Compare the means of three or more groups** | Continuous data | **ANOVA (Analysis of Variance)** | Compare the effect of different caffeine doses: 0 mg, 50 mg, 100 mg, 150 mg |
| **Find a relationship between two numerical variables** | Two continuous variables | **Pearson's correlation (r)** | Relationship between hours of sleep and memory test score |
| **Predict one variable from another** | Continuous variables | **Linear regression** | Predict test score from the number of cups of coffee consumed |
| **Examine the relationship between categories** | Categorical data | **Chi-squared test (χ²)** | Relationship between gender and preference for coffee vs. tea |
| **Compare groups with small samples or non-normal data** | Any data | **Non-parametric tests** (Mann-Whitney U, Wilcoxon) | Comparing groups with small samples |

**More on the most important tests:**

**1. Student's t-test**
- *When to use*: to compare the means of two groups.
- *Assumptions*: data is approximately normally distributed, samples are independent.
- *Result*: t-statistic and p-value.
- *Example of interpretation:
  (The original text seems to be incomplete here, ending abruptly before an example of interpretation. I will complete it based on the previous context.)*
  *Example interpretation*: "Based on the t-test, we found a statistically significant difference (p < 0.05) between the memory scores of the caffeine group and the placebo group, suggesting caffeine had a real effect."

---

#### Stage 5: Interpreting Results

**Critical evaluation of the results** includes:

1.  **P-value**: the probability of getting the observed result if the null hypothesis is true.
    - p < 0.05: the result is statistically significant.
    - p ≥ 0.05: insufficient grounds to reject H₀.

2.  **Effect Size**: the practical significance of the result.
    - Cohen's d for differences between groups.
    - R² for explained variance.
    - Importance: statistical significance ≠ practical significance.

3.  **Confidence Intervals**: the range of possible values for the true effect in the population.

**Analysis of systematic errors and limitations**:
- Sampling error: how representative the sample is.
- Information error: inaccuracies in measurements or classification.
- Confounding: the influence of third variables on the studied relationship.

### 3.4. Example: Sagan's Hypothesis about Venus

A classic example of the successful application of the scientific method is Carl Sagan's prediction about the climate of Venus. In 1960, when the prevailing view was that Venus might be habitable, Sagan hypothesized that the planet's surface was dry and had an extremely high temperature.

This hypothesis was:
- **Specific**—it predicted a temperature of about 500°C.
- **Falsifiable**—it could be disproven by measurements.
- **Testable**—it allowed for experimental verification.

In 1962, the Mariner 2 automated space probe confirmed Sagan's prediction, which was a triumph of scientific foresight.

---

### 3.5. Modern Methods for Classifying and Systematizing Data

**Hierarchical methods** of data organization follow a tree-like structure:
- Each object belongs to only one class at each level.
- There is a strict sequence of classification features.
- Application: biological taxonomy, library systems.

**Faceted methods** allow for parallel classification:
- Independent groupings based on various features.
- Flexibility in choosing classification criteria.
- Application: online catalogs, product databases.

**Machine learning methods** for processing large volumes of data:
- Supervised learning: classification based on labeled data.
- Unsupervised learning: clustering and identifying hidden structures.
- Bayesian methods: incorporating prior knowledge into classification.

---

### 3.6. The Role of Observation and Experiment

It is important to understand that observations and questions in science are interconnected: "questions determine observations, but observations also determine questions—in fact, they should be considered exclusively together." Science deals solely with the natural world—"atoms, people, galaxies, society, plants"—while the supernatural lies outside the scope of scientific inquiry.

**Criteria for a quality experiment**:
- **Reproducibility**: Other researchers must be able to obtain similar results.
- **Controllability**: Isolation of the factor being studied from extraneous influences.
- **Measurability**: Use of objective, quantitative indicators.
- **Ethicality**: Adherence to the principles of research ethics.


---

## 4. Problems of Verification and Falsification

### 4.1. Popper’s Criterion

Karl Popper introduced the concept of **falsifiability** as a criterion for scientific theories. A scientific hypothesis must make specific predictions that can, in principle, be disproven by experiment. This does not mean that a falsifiable hypothesis is necessarily true — for example, the claim “the Sun is made entirely of pistachio ice cream” meets Popper’s criterion but is clearly false.

### 4.2. Russell’s Teapot

Bertrand Russell illustrated the problem of unfalsifiable claims with his famous analogy: “If I were to suggest that between the Earth and Mars there is a china teapot revolving about the Sun in an elliptical orbit… no one could disprove my assertion if I added that the teapot is too small to be revealed even by our most powerful telescopes.”

Russell’s Teapot demonstrates a fundamental principle: **the burden of proof lies on the one making the claim, not on the one refuting it**. The unfalsifiability of a claim does not make it true or even plausible.

### 4.3. The Problem of Induction

The scientific method often relies on inductive reasoning — moving from specific observations to general laws. However, induction does not logically guarantee the truth of conclusions. Even repeated confirmation of a hypothesis does not prove it definitively — alternative explanations always exist.

Moreover, the same experimental data can support multiple contradictory theories. For example, Lavoisier’s experiments with mercury oxide could be explained both within the oxygen theory and within the phlogiston theory when supplemented with suitable auxiliary hypotheses.

---

## 5. The Limits of the Scientific Method and the Role of Rationality

### 5.1. When Science Is Powerless

Eliezer Yudkowsky raises an important problem: what to do in situations where the traditional scientific method cannot yet provide an answer? There are questions of enormous importance that cannot currently be tested experimentally but still require rational consideration.

Examples include:

* **Cryonics** — the possibility of preserving a person through freezing and future revival
* **Macroscopic quantum superpositions** — the behavior of quantum systems at the macroscopic level
* **Evolutionary psychology** — many of its hypotheses cannot be directly tested

### 5.2. The Bayesian Approach

In such cases, the Bayesian approach to evaluating hypotheses becomes useful. The key principle: **absence of evidence is evidence of absence only when evidence is expected**.

For example:

* If snake oil truly cured cancer, we would expect numerous successful studies
* But the absence of transitional fossil forms does not disprove evolution, because fossilization is extremely rare

### 5.3. The Example of Cryonics

Let us consider cryonics as an example of rational analysis in the absence of direct evidence. Traditional science might say: “Not proven — therefore it doesn’t work.” But this is a misapplication of the scientific method.

From a Bayesian perspective, it is important to note:

* There are no fundamental physical barriers to restoring frozen tissues
* The absence of successful revivals is explained by technological limitations, not by inherent impossibility
* Information-theoretic death (destruction of brain structure) is different from clinical death

---

## 6. Pseudoscience and Scientific Thinking

### 6.1. Signs of Pseudoscience

Feynman warns of the dangers of pseudoscience — the imitation of scientific methods without understanding their essence. Main signs of a pseudoscientific approach:

1. **Copying form without substance** — conducting experiments, compiling statistics without understanding the purpose
2. **Lack of self-criticism** — unwillingness to subject one’s ideas to serious testing
3. **Seeking confirmation instead of refutation** — selectively choosing supporting data

### 6.2. Mysterious Answers to Mysterious Questions

Yudkowsky identifies four hallmarks of pseudoscientific explanations:

1. **The explanation acts as a stopper for curiosity**, not as a predictive tool
2. **The hypothesis has no moving parts** — the mystery is attributed to an indivisible essence
3. **The authors cherish their ignorance**, boasting that the phenomenon “transcends ordinary science”
4. **After the explanation, the phenomenon remains just as mysterious** as before

A classic example is Roger Penrose’s attempt to explain consciousness through “quantum gravity.” Even if this hypothesis were correct, it would not explain why the brain thinks “I think, therefore I am,” or why the color red appears as it does.

### 6.3. Media and the Spread of Pseudoscience

Modern media facilitate the spread of pseudoscientific ideas. As the editor-in-chief of *Weekly World News* put it: “We’re a tabloid — why would we give up a good story?” Skeptical analysis doesn’t boost circulation, so outlets prefer sensational but unreliable material.

The problem is compounded by the fact that “those pedantically sticking to verified facts” lose audience share to less scrupulous competitors.

---

## 7. Cognitive Biases in Scientific Inquiry

### 7.1. The Problem of Human Rationality

Thomas Gilovich, in *How We Know What Isn’t So*, demonstrates systematic errors of human thinking:

* Confusion with numbers and statistics
* Dismissing inconvenient evidence
* Susceptibility to external influence

Particularly dangerous is the tendency “to seek and fit evidence to our desires, discarding that which contradicts them.”

### 7.2. Motivated Reasoning

People are prone to **motivated reasoning** — seeking arguments to support a desired conclusion rather than objectively evaluating evidence. This manifests in:

* Selective attention to confirming facts
* Ignoring contradicting data
* Double standards in evaluating sources

### 7.3. The Role of Emotions and Desires

“The more intensely we want to believe, the greater the care that is required,” warns Thomas Huxley. Strong emotional preferences distort the evaluation of evidence. Therefore, it is critically important to:

* Recognize one’s own biases
* Actively seek refuting data
* Engage independent critics

---

## 8. Science and Society: Challenges of the Modern Era

### 8.1. Social Consequences of Anti-Scientific Thinking

History knows tragic examples of rejecting rational thinking. The *Malleus Maleficarum* (1487) — “one of the most terrifying documents in human history” — shows what happens when dogmas and prejudices replace evidence.

### 8.2. Challenges for Education

Feynman warns: “We live in an unscientific age in which almost all the machinery of communication — television, words, books — is unscientific.” This creates special challenges for education:

* How to distinguish science from its imitation?
* How to develop critical thinking in the age of information overload?
* How to resist “intellectual tyranny done in the name of science”?

### 8.3. The Role of Expertise

A paradox of modern society: on the one hand, knowledge is becoming increasingly specialized; on the other — distrust of experts is growing. As Sagan asks: “By the way, how does society reward those who question its social and economic dogmas?”

It is important to distinguish healthy skepticism from blanket rejection of expert knowledge.

---

## 9. Conclusion

Studying the nature of science, the scientific method, and scientific thinking leads to several key conclusions:

### 9.1. Science as a Process, Not a Dogma

Science is not a set of immutable truths but a dynamic process of constantly checking and revising our understanding of the world. As Ann Druyan emphasizes, science continually “whispers to the human being: remember, you’re not as good at this as you think.”

### 9.2. Limitations of the Traditional Scientific Method

Although the hypothetico-deductive method remains the foundation of scientific inquiry, it has significant limitations:

* Not all important questions are experimentally testable
* Induction does not logically guarantee truth
* Alternative explanations are always possible

### 9.3. The Necessity of Rational Thinking

In situations where traditional science is powerless, rational thinking based on the Bayesian approach comes to the rescue. Key principles:

* Assessing the prior probability of hypotheses
* Distinguishing between “not proven” and “false”
* Considering context when interpreting absence of evidence

### 9.4. The Importance of Critical Thinking

Fighting pseudoscience and cognitive biases requires developing critical thinking:

* The ability to distinguish form from substance in the scientific method
* Willingness to question even appealing ideas
* Understanding the limits of applicability of different methods of inquiry

### 9.5. Social Responsibility

Science does not exist in a vacuum — it is inseparably linked to society. Understanding the principles of scientific thinking is critical for:

* Making informed decisions under uncertainty
* Resisting manipulation and misinformation
* Preserving rational discourse in public life

### 9.6. Balancing Skepticism and Openness

As Feynman notes, passing knowledge to future generations requires “a delicate balance between respect and skepticism.” We must “teach and accept the past, and doubt it — and this balance requires great skill.”

### 9.7. Prospects for Development

The future of scientific inquiry will likely be characterized by:

* Integrating traditional scientific methods with Bayesian approaches
* Developing interdisciplinary research
* Using artificial intelligence to process large datasets
* New forms of collective cognition

**Final Thought**

“There’s plenty of wonders in the universe without inventing any,” Sagan reminds us. Scientific inquiry does not impoverish the world but reveals its true beauty and complexity. Understanding the principles of science and rational thinking is not just an academic task but a necessary condition for navigating the complexity of the modern world.

Of all disciplines, only science “contains within itself the lesson that the greatest teachers of the past can be wrong.” This lesson of humility before the complexity of the world, of readiness to revise one’s beliefs, and of striving for truth remains as relevant as ever.

---

## References

1. Sagan, C. *The Demon-Haunted World: Science as a Candle in the Dark*
2. Feynman, R. *The Character of Physical Law*
3. Feynman, R. “What Is Science?” *The Physics Teacher*, 1968
4. Gilovich, T. *How We Know What Isn’t So: The Fallibility of Human Reason in Everyday Life*
5. Popper, K. *The Logic of Scientific Discovery*
6. Russell, B. *Is There a God?* Illustrated Magazine, 1952
7. Yudkowsky, E. *Rationality: From AI to Zombies*
8. Hacking, I. *Representing and Intervening*
9. Kuhn, T. *The Structure of Scientific Revolutions*
10. Lakatos, I. *The Methodology of Scientific Research Programmes*